{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":56537,"databundleVersionId":8877088,"sourceType":"competition"},{"sourceId":8954614,"sourceType":"datasetVersion","datasetId":5389055},{"sourceId":8954980,"sourceType":"datasetVersion","datasetId":5389276}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport os\nimport random\nimport time\nimport torch\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics.regression import R2Score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-17T14:03:05.164581Z","iopub.execute_input":"2024-07-17T14:03:05.165502Z","iopub.status.idle":"2024-07-17T14:03:13.647171Z","shell.execute_reply.started":"2024-07-17T14:03:05.165462Z","shell.execute_reply":"2024-07-17T14:03:13.646224Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/\"\nBATCH_SIZE = 13000\nMIN_STD = 1e-8\nSCHEDULER_PATIENCE = 3\nSCHEDULER_FACTOR = 10**(-0.5)\nEPOCHS = 70\nPATIENCE = 6\nPRINT_FREQ = 50","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:03:13.649217Z","iopub.execute_input":"2024-07-17T14:03:13.649802Z","iopub.status.idle":"2024-07-17T14:03:13.656041Z","shell.execute_reply.started":"2024-07-17T14:03:13.649765Z","shell.execute_reply":"2024-07-17T14:03:13.655041Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def format_time(elapsed):\n    \"\"\"Take a time in seconds and return a string hh:mm:ss.\"\"\"\n    elapsed_rounded = int(round((elapsed)))\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:03:13.657156Z","iopub.execute_input":"2024-07-17T14:03:13.657417Z","iopub.status.idle":"2024-07-17T14:03:13.667622Z","shell.execute_reply.started":"2024-07-17T14:03:13.657394Z","shell.execute_reply":"2024-07-17T14:03:13.666734Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed_val=1325):\n    \"\"\"Seed everything.\"\"\"\n    random.seed(seed_val)\n    np.random.seed(seed_val)\n    torch.manual_seed(seed_val)\n    torch.cuda.manual_seed_all(seed_val)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:03:13.670286Z","iopub.execute_input":"2024-07-17T14:03:13.671064Z","iopub.status.idle":"2024-07-17T14:03:13.678639Z","shell.execute_reply.started":"2024-07-17T14:03:13.671034Z","shell.execute_reply":"2024-07-17T14:03:13.677612Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def columns_with_low_variance(X):\n    variances = X.select([pl.col(column).var() for column in X.columns])\n#     variances\n    low_variance_cols = [col for col, var in zip(X.columns, variances.row(0)) if var < 1e-6]\n    print(len(low_variance_cols))\n    return low_variance_cols\n# Define normalization functions\ndef normalize_min_max(x, mean, min_val, max_val):\n    return (x - mean) / (max_val - min_val)\n\ndef normalize_div_max(x, max_val):\n    return x / max_val\n\ndef normalize_exp(x, lambda_val):\n    return 1 - np.exp(-lambda_val * x)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:03:13.679911Z","iopub.execute_input":"2024-07-17T14:03:13.680291Z","iopub.status.idle":"2024-07-17T14:03:13.690813Z","shell.execute_reply.started":"2024-07-17T14:03:13.680246Z","shell.execute_reply":"2024-07-17T14:03:13.689825Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# df_train = pl.read_csv(DATA_PATH + \"leap-atmospheric-physics-ai-climsim/train.csv\", n_rows=100)\ndef normalize(df_train,FEAT_COLS):\n    FEAT_COLS = df_train.columns[1:557]\n    TARGET_COLS = df_train.columns[557:]\n    state_t_cols = []#(x-mean)/(max-min)\n    state_q0001_cols = []# no norm\n    state_q0002_cols = []#1-exp()\n    state_q0003_cols = []#1-exp()\n    state_u_cols = []#(x-mean)/(max-min)\n    state_v_cols = []#(x-mean)/(max-min)\n    pbuf_ozone_cols = []#(x-mean)/(max-min)\n    pbuf_CH4_cols = []#(x-mean)/(max-min)\n    pbuf_N2O_cols = []#(x-mean)/(max-min)\n    centered_min_max_cols = ['state_ps','pbuf_TAUX','pbuf_TAUY','pbuf_COSZRS','cam_in_ALDIF','cam_in_ALDIR','cam_in_ASDIF','cam_in_ASDIR','cam_in_LWUP','cam_in_SNOWHLAND']\n    min_max_scaling_cols = ['pbuf_SOLIN','pbuf_LHFLX','pbuf_SHFLX']\n    expo_scaling_cols = []\n\n    for col in FEAT_COLS:\n        if 'state_t'in col:\n            state_t_cols.append(col)\n            centered_min_max_cols.append(col)\n        elif 'state_q0001' in col:\n            state_q0001_cols.append(col)\n        elif 'state_q0002' in col:\n            state_q0002_cols.append(col)\n            expo_scaling_cols.append(col)\n        elif 'state_q0003' in col:\n            state_q0003_cols.append(col)\n            expo_scaling_cols.append(col)\n        elif 'state_u' in col:\n            state_u_cols.append(col)\n            centered_min_max_cols.append(col)\n        elif 'state_v' in col:\n            state_v_cols.append(col)\n            centered_min_max_cols.append(col)\n        elif 'pbuf_ozone' in col:\n            pbuf_ozone_cols.append(col)\n            centered_min_max_cols.append(col)\n        elif 'pbuf_CH4' in col:\n            pbuf_CH4_cols.append(col)\n            centered_min_max_cols.append(col)\n        elif 'pbuf_N2O' in col:\n            pbuf_N2O_cols.append(col)\n            centered_min_max_cols.append(col)\n    lis_vector_features = [state_t_cols,state_q0001_cols,state_q0002_cols,state_q0003_cols,state_u_cols,state_v_cols,pbuf_ozone_cols,pbuf_CH4_cols,pbuf_N2O_cols]\n    \n    for col in FEAT_COLS:\n        if col in centered_min_max_cols:\n            mean = df_train[col].mean()\n            min_val = df_train[col].min()\n            max_val = df_train[col].max()\n            if not (min_val > 0 and max_val < 1):\n                df_train = df_train.with_columns(normalize_min_max(pl.col(col), mean, min_val, max_val).alias(col))\n        if col in min_max_scaling_cols:\n            min_val = df_train[col].min()\n            max_val = df_train[col].max()\n            if not (min_val > 0 and max_val < 1):\n                df_train = df_train.with_columns(normalize_div_max(pl.col(col), max_val).alias(col))\n        if col in expo_scaling_cols:\n            try:\n                lambda_val = 1/df_train[col].filter(df_train[col]>1e-7).mean()\n            except Exception as e:\n                lambda_val = 1\n            df_train = df_train.with_columns(normalize_exp(pl.col(col), lambda_val).alias(col))\n    return df_train,lis_vector_features","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:03:13.692115Z","iopub.execute_input":"2024-07-17T14:03:13.692434Z","iopub.status.idle":"2024-07-17T14:03:13.710492Z","shell.execute_reply.started":"2024-07-17T14:03:13.692408Z","shell.execute_reply":"2024-07-17T14:03:13.709528Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"ts = time.time()\n\nweights = pd.read_csv(DATA_PATH + \"leap-atmospheric-physics-ai-climsim/sample_submission.csv\", nrows=1)\ndel weights['sample_id']\nweights = weights.T\nweights = weights.to_dict()[0]\nbatch_size = 2_500_000\nbatch_number = 2  # Change this to 2, 3, etc., to load subsequent batches\nskip_rows = batch_size * batch_number\n\ndf_header = pl.read_csv(DATA_PATH + \"leap-atmospheric-physics-ai-climsim/train.csv\", n_rows=1)\ncolumn_names = df_header.columns\n# print(column_names)\n\ndf_train = pl.read_csv(DATA_PATH + \"leap-atmospheric-physics-ai-climsim/train.csv\", n_rows=2_500_000, skip_rows_after_header=skip_rows)#2500000\n\n# for target in weights:\n#     df_train = df_train.with_columns(pl.col(target).mul(weights[target]))\n\nprint(\"Time to read dataset:\", format_time(time.time()-ts), flush=True)\n\nFEAT_COLS = df_train.columns[1:557]\nTARGET_COLS = df_train.columns[557:]\ndf_train,list_vector_features = normalize(df_train,FEAT_COLS)\nfor col in FEAT_COLS:\n    df_train = df_train.with_columns(pl.col(col).cast(pl.Float32))\n\nfor col in TARGET_COLS:\n    df_train = df_train.with_columns(pl.col(col).cast(pl.Float32))\n\n \n    \nx_train = df_train.select(FEAT_COLS).to_numpy()\n# low_variance_cols = columns_with_low_variance(x_train).to_numpy()\n# x_train = x_train.drop(low_variance_cols).to_numpy()\ny_train = df_train.select(TARGET_COLS).to_numpy()\n\n# del df_train\n# gc.collect()\n\n# Normalization of training data\n# mx = x_train.mean(axis=0)\n# sx = np.maximum(x_train.std(axis=0), MIN_STD)\n# # print('mean: ', mx, ' variance: ' sx)\n# x_train = (x_train - mx.reshape(1,-1)) / sx.reshape(1,-1)\n\nmy = y_train.mean(axis=0)\nsy = np.maximum(np.sqrt((y_train*y_train).mean(axis=0)), MIN_STD)\ny_train = (y_train - my.reshape(1,-1)) / sy.reshape(1,-1)\n\nprint(\"Time after processing data:\", format_time(time.time()-ts), flush=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:03:13.711829Z","iopub.execute_input":"2024-07-17T14:03:13.712126Z","iopub.status.idle":"2024-07-17T14:45:24.065128Z","shell.execute_reply.started":"2024-07-17T14:03:13.712100Z","shell.execute_reply":"2024-07-17T14:45:24.064132Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Time to read dataset: 0:41:41\nTime after processing data: 0:42:10\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# checking data ","metadata":{}},{"cell_type":"code","source":"df_train.columns","metadata":{"execution":{"iopub.status.busy":"2024-07-16T16:45:41.393534Z","iopub.execute_input":"2024-07-16T16:45:41.394090Z","iopub.status.idle":"2024-07-16T16:45:41.429747Z","shell.execute_reply.started":"2024-07-16T16:45:41.394035Z","shell.execute_reply":"2024-07-16T16:45:41.428613Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['sample_id',\n 'state_t_0',\n 'state_t_1',\n 'state_t_2',\n 'state_t_3',\n 'state_t_4',\n 'state_t_5',\n 'state_t_6',\n 'state_t_7',\n 'state_t_8',\n 'state_t_9',\n 'state_t_10',\n 'state_t_11',\n 'state_t_12',\n 'state_t_13',\n 'state_t_14',\n 'state_t_15',\n 'state_t_16',\n 'state_t_17',\n 'state_t_18',\n 'state_t_19',\n 'state_t_20',\n 'state_t_21',\n 'state_t_22',\n 'state_t_23',\n 'state_t_24',\n 'state_t_25',\n 'state_t_26',\n 'state_t_27',\n 'state_t_28',\n 'state_t_29',\n 'state_t_30',\n 'state_t_31',\n 'state_t_32',\n 'state_t_33',\n 'state_t_34',\n 'state_t_35',\n 'state_t_36',\n 'state_t_37',\n 'state_t_38',\n 'state_t_39',\n 'state_t_40',\n 'state_t_41',\n 'state_t_42',\n 'state_t_43',\n 'state_t_44',\n 'state_t_45',\n 'state_t_46',\n 'state_t_47',\n 'state_t_48',\n 'state_t_49',\n 'state_t_50',\n 'state_t_51',\n 'state_t_52',\n 'state_t_53',\n 'state_t_54',\n 'state_t_55',\n 'state_t_56',\n 'state_t_57',\n 'state_t_58',\n 'state_t_59',\n 'state_q0001_0',\n 'state_q0001_1',\n 'state_q0001_2',\n 'state_q0001_3',\n 'state_q0001_4',\n 'state_q0001_5',\n 'state_q0001_6',\n 'state_q0001_7',\n 'state_q0001_8',\n 'state_q0001_9',\n 'state_q0001_10',\n 'state_q0001_11',\n 'state_q0001_12',\n 'state_q0001_13',\n 'state_q0001_14',\n 'state_q0001_15',\n 'state_q0001_16',\n 'state_q0001_17',\n 'state_q0001_18',\n 'state_q0001_19',\n 'state_q0001_20',\n 'state_q0001_21',\n 'state_q0001_22',\n 'state_q0001_23',\n 'state_q0001_24',\n 'state_q0001_25',\n 'state_q0001_26',\n 'state_q0001_27',\n 'state_q0001_28',\n 'state_q0001_29',\n 'state_q0001_30',\n 'state_q0001_31',\n 'state_q0001_32',\n 'state_q0001_33',\n 'state_q0001_34',\n 'state_q0001_35',\n 'state_q0001_36',\n 'state_q0001_37',\n 'state_q0001_38',\n 'state_q0001_39',\n 'state_q0001_40',\n 'state_q0001_41',\n 'state_q0001_42',\n 'state_q0001_43',\n 'state_q0001_44',\n 'state_q0001_45',\n 'state_q0001_46',\n 'state_q0001_47',\n 'state_q0001_48',\n 'state_q0001_49',\n 'state_q0001_50',\n 'state_q0001_51',\n 'state_q0001_52',\n 'state_q0001_53',\n 'state_q0001_54',\n 'state_q0001_55',\n 'state_q0001_56',\n 'state_q0001_57',\n 'state_q0001_58',\n 'state_q0001_59',\n 'state_q0002_0',\n 'state_q0002_1',\n 'state_q0002_2',\n 'state_q0002_3',\n 'state_q0002_4',\n 'state_q0002_5',\n 'state_q0002_6',\n 'state_q0002_7',\n 'state_q0002_8',\n 'state_q0002_9',\n 'state_q0002_10',\n 'state_q0002_11',\n 'state_q0002_12',\n 'state_q0002_13',\n 'state_q0002_14',\n 'state_q0002_15',\n 'state_q0002_16',\n 'state_q0002_17',\n 'state_q0002_18',\n 'state_q0002_19',\n 'state_q0002_20',\n 'state_q0002_21',\n 'state_q0002_22',\n 'state_q0002_23',\n 'state_q0002_24',\n 'state_q0002_25',\n 'state_q0002_26',\n 'state_q0002_27',\n 'state_q0002_28',\n 'state_q0002_29',\n 'state_q0002_30',\n 'state_q0002_31',\n 'state_q0002_32',\n 'state_q0002_33',\n 'state_q0002_34',\n 'state_q0002_35',\n 'state_q0002_36',\n 'state_q0002_37',\n 'state_q0002_38',\n 'state_q0002_39',\n 'state_q0002_40',\n 'state_q0002_41',\n 'state_q0002_42',\n 'state_q0002_43',\n 'state_q0002_44',\n 'state_q0002_45',\n 'state_q0002_46',\n 'state_q0002_47',\n 'state_q0002_48',\n 'state_q0002_49',\n 'state_q0002_50',\n 'state_q0002_51',\n 'state_q0002_52',\n 'state_q0002_53',\n 'state_q0002_54',\n 'state_q0002_55',\n 'state_q0002_56',\n 'state_q0002_57',\n 'state_q0002_58',\n 'state_q0002_59',\n 'state_q0003_0',\n 'state_q0003_1',\n 'state_q0003_2',\n 'state_q0003_3',\n 'state_q0003_4',\n 'state_q0003_5',\n 'state_q0003_6',\n 'state_q0003_7',\n 'state_q0003_8',\n 'state_q0003_9',\n 'state_q0003_10',\n 'state_q0003_11',\n 'state_q0003_12',\n 'state_q0003_13',\n 'state_q0003_14',\n 'state_q0003_15',\n 'state_q0003_16',\n 'state_q0003_17',\n 'state_q0003_18',\n 'state_q0003_19',\n 'state_q0003_20',\n 'state_q0003_21',\n 'state_q0003_22',\n 'state_q0003_23',\n 'state_q0003_24',\n 'state_q0003_25',\n 'state_q0003_26',\n 'state_q0003_27',\n 'state_q0003_28',\n 'state_q0003_29',\n 'state_q0003_30',\n 'state_q0003_31',\n 'state_q0003_32',\n 'state_q0003_33',\n 'state_q0003_34',\n 'state_q0003_35',\n 'state_q0003_36',\n 'state_q0003_37',\n 'state_q0003_38',\n 'state_q0003_39',\n 'state_q0003_40',\n 'state_q0003_41',\n 'state_q0003_42',\n 'state_q0003_43',\n 'state_q0003_44',\n 'state_q0003_45',\n 'state_q0003_46',\n 'state_q0003_47',\n 'state_q0003_48',\n 'state_q0003_49',\n 'state_q0003_50',\n 'state_q0003_51',\n 'state_q0003_52',\n 'state_q0003_53',\n 'state_q0003_54',\n 'state_q0003_55',\n 'state_q0003_56',\n 'state_q0003_57',\n 'state_q0003_58',\n 'state_q0003_59',\n 'state_u_0',\n 'state_u_1',\n 'state_u_2',\n 'state_u_3',\n 'state_u_4',\n 'state_u_5',\n 'state_u_6',\n 'state_u_7',\n 'state_u_8',\n 'state_u_9',\n 'state_u_10',\n 'state_u_11',\n 'state_u_12',\n 'state_u_13',\n 'state_u_14',\n 'state_u_15',\n 'state_u_16',\n 'state_u_17',\n 'state_u_18',\n 'state_u_19',\n 'state_u_20',\n 'state_u_21',\n 'state_u_22',\n 'state_u_23',\n 'state_u_24',\n 'state_u_25',\n 'state_u_26',\n 'state_u_27',\n 'state_u_28',\n 'state_u_29',\n 'state_u_30',\n 'state_u_31',\n 'state_u_32',\n 'state_u_33',\n 'state_u_34',\n 'state_u_35',\n 'state_u_36',\n 'state_u_37',\n 'state_u_38',\n 'state_u_39',\n 'state_u_40',\n 'state_u_41',\n 'state_u_42',\n 'state_u_43',\n 'state_u_44',\n 'state_u_45',\n 'state_u_46',\n 'state_u_47',\n 'state_u_48',\n 'state_u_49',\n 'state_u_50',\n 'state_u_51',\n 'state_u_52',\n 'state_u_53',\n 'state_u_54',\n 'state_u_55',\n 'state_u_56',\n 'state_u_57',\n 'state_u_58',\n 'state_u_59',\n 'state_v_0',\n 'state_v_1',\n 'state_v_2',\n 'state_v_3',\n 'state_v_4',\n 'state_v_5',\n 'state_v_6',\n 'state_v_7',\n 'state_v_8',\n 'state_v_9',\n 'state_v_10',\n 'state_v_11',\n 'state_v_12',\n 'state_v_13',\n 'state_v_14',\n 'state_v_15',\n 'state_v_16',\n 'state_v_17',\n 'state_v_18',\n 'state_v_19',\n 'state_v_20',\n 'state_v_21',\n 'state_v_22',\n 'state_v_23',\n 'state_v_24',\n 'state_v_25',\n 'state_v_26',\n 'state_v_27',\n 'state_v_28',\n 'state_v_29',\n 'state_v_30',\n 'state_v_31',\n 'state_v_32',\n 'state_v_33',\n 'state_v_34',\n 'state_v_35',\n 'state_v_36',\n 'state_v_37',\n 'state_v_38',\n 'state_v_39',\n 'state_v_40',\n 'state_v_41',\n 'state_v_42',\n 'state_v_43',\n 'state_v_44',\n 'state_v_45',\n 'state_v_46',\n 'state_v_47',\n 'state_v_48',\n 'state_v_49',\n 'state_v_50',\n 'state_v_51',\n 'state_v_52',\n 'state_v_53',\n 'state_v_54',\n 'state_v_55',\n 'state_v_56',\n 'state_v_57',\n 'state_v_58',\n 'state_v_59',\n 'state_ps',\n 'pbuf_SOLIN',\n 'pbuf_LHFLX',\n 'pbuf_SHFLX',\n 'pbuf_TAUX',\n 'pbuf_TAUY',\n 'pbuf_COSZRS',\n 'cam_in_ALDIF',\n 'cam_in_ALDIR',\n 'cam_in_ASDIF',\n 'cam_in_ASDIR',\n 'cam_in_LWUP',\n 'cam_in_ICEFRAC',\n 'cam_in_LANDFRAC',\n 'cam_in_OCNFRAC',\n 'cam_in_SNOWHLAND',\n 'pbuf_ozone_0',\n 'pbuf_ozone_1',\n 'pbuf_ozone_2',\n 'pbuf_ozone_3',\n 'pbuf_ozone_4',\n 'pbuf_ozone_5',\n 'pbuf_ozone_6',\n 'pbuf_ozone_7',\n 'pbuf_ozone_8',\n 'pbuf_ozone_9',\n 'pbuf_ozone_10',\n 'pbuf_ozone_11',\n 'pbuf_ozone_12',\n 'pbuf_ozone_13',\n 'pbuf_ozone_14',\n 'pbuf_ozone_15',\n 'pbuf_ozone_16',\n 'pbuf_ozone_17',\n 'pbuf_ozone_18',\n 'pbuf_ozone_19',\n 'pbuf_ozone_20',\n 'pbuf_ozone_21',\n 'pbuf_ozone_22',\n 'pbuf_ozone_23',\n 'pbuf_ozone_24',\n 'pbuf_ozone_25',\n 'pbuf_ozone_26',\n 'pbuf_ozone_27',\n 'pbuf_ozone_28',\n 'pbuf_ozone_29',\n 'pbuf_ozone_30',\n 'pbuf_ozone_31',\n 'pbuf_ozone_32',\n 'pbuf_ozone_33',\n 'pbuf_ozone_34',\n 'pbuf_ozone_35',\n 'pbuf_ozone_36',\n 'pbuf_ozone_37',\n 'pbuf_ozone_38',\n 'pbuf_ozone_39',\n 'pbuf_ozone_40',\n 'pbuf_ozone_41',\n 'pbuf_ozone_42',\n 'pbuf_ozone_43',\n 'pbuf_ozone_44',\n 'pbuf_ozone_45',\n 'pbuf_ozone_46',\n 'pbuf_ozone_47',\n 'pbuf_ozone_48',\n 'pbuf_ozone_49',\n 'pbuf_ozone_50',\n 'pbuf_ozone_51',\n 'pbuf_ozone_52',\n 'pbuf_ozone_53',\n 'pbuf_ozone_54',\n 'pbuf_ozone_55',\n 'pbuf_ozone_56',\n 'pbuf_ozone_57',\n 'pbuf_ozone_58',\n 'pbuf_ozone_59',\n 'pbuf_CH4_0',\n 'pbuf_CH4_1',\n 'pbuf_CH4_2',\n 'pbuf_CH4_3',\n 'pbuf_CH4_4',\n 'pbuf_CH4_5',\n 'pbuf_CH4_6',\n 'pbuf_CH4_7',\n 'pbuf_CH4_8',\n 'pbuf_CH4_9',\n 'pbuf_CH4_10',\n 'pbuf_CH4_11',\n 'pbuf_CH4_12',\n 'pbuf_CH4_13',\n 'pbuf_CH4_14',\n 'pbuf_CH4_15',\n 'pbuf_CH4_16',\n 'pbuf_CH4_17',\n 'pbuf_CH4_18',\n 'pbuf_CH4_19',\n 'pbuf_CH4_20',\n 'pbuf_CH4_21',\n 'pbuf_CH4_22',\n 'pbuf_CH4_23',\n 'pbuf_CH4_24',\n 'pbuf_CH4_25',\n 'pbuf_CH4_26',\n 'pbuf_CH4_27',\n 'pbuf_CH4_28',\n 'pbuf_CH4_29',\n 'pbuf_CH4_30',\n 'pbuf_CH4_31',\n 'pbuf_CH4_32',\n 'pbuf_CH4_33',\n 'pbuf_CH4_34',\n 'pbuf_CH4_35',\n 'pbuf_CH4_36',\n 'pbuf_CH4_37',\n 'pbuf_CH4_38',\n 'pbuf_CH4_39',\n 'pbuf_CH4_40',\n 'pbuf_CH4_41',\n 'pbuf_CH4_42',\n 'pbuf_CH4_43',\n 'pbuf_CH4_44',\n 'pbuf_CH4_45',\n 'pbuf_CH4_46',\n 'pbuf_CH4_47',\n 'pbuf_CH4_48',\n 'pbuf_CH4_49',\n 'pbuf_CH4_50',\n 'pbuf_CH4_51',\n 'pbuf_CH4_52',\n 'pbuf_CH4_53',\n 'pbuf_CH4_54',\n 'pbuf_CH4_55',\n 'pbuf_CH4_56',\n 'pbuf_CH4_57',\n 'pbuf_CH4_58',\n 'pbuf_CH4_59',\n 'pbuf_N2O_0',\n 'pbuf_N2O_1',\n 'pbuf_N2O_2',\n 'pbuf_N2O_3',\n 'pbuf_N2O_4',\n 'pbuf_N2O_5',\n 'pbuf_N2O_6',\n 'pbuf_N2O_7',\n 'pbuf_N2O_8',\n 'pbuf_N2O_9',\n 'pbuf_N2O_10',\n 'pbuf_N2O_11',\n 'pbuf_N2O_12',\n 'pbuf_N2O_13',\n 'pbuf_N2O_14',\n 'pbuf_N2O_15',\n 'pbuf_N2O_16',\n 'pbuf_N2O_17',\n 'pbuf_N2O_18',\n 'pbuf_N2O_19',\n 'pbuf_N2O_20',\n 'pbuf_N2O_21',\n 'pbuf_N2O_22',\n 'pbuf_N2O_23',\n 'pbuf_N2O_24',\n 'pbuf_N2O_25',\n 'pbuf_N2O_26',\n 'pbuf_N2O_27',\n 'pbuf_N2O_28',\n 'pbuf_N2O_29',\n 'pbuf_N2O_30',\n 'pbuf_N2O_31',\n 'pbuf_N2O_32',\n 'pbuf_N2O_33',\n 'pbuf_N2O_34',\n 'pbuf_N2O_35',\n 'pbuf_N2O_36',\n 'pbuf_N2O_37',\n 'pbuf_N2O_38',\n 'pbuf_N2O_39',\n 'pbuf_N2O_40',\n 'pbuf_N2O_41',\n 'pbuf_N2O_42',\n 'pbuf_N2O_43',\n 'pbuf_N2O_44',\n 'pbuf_N2O_45',\n 'pbuf_N2O_46',\n 'pbuf_N2O_47',\n 'pbuf_N2O_48',\n 'pbuf_N2O_49',\n 'pbuf_N2O_50',\n 'pbuf_N2O_51',\n 'pbuf_N2O_52',\n 'pbuf_N2O_53',\n 'pbuf_N2O_54',\n 'pbuf_N2O_55',\n 'pbuf_N2O_56',\n 'pbuf_N2O_57',\n 'pbuf_N2O_58',\n 'pbuf_N2O_59',\n 'ptend_t_0',\n 'ptend_t_1',\n 'ptend_t_2',\n 'ptend_t_3',\n 'ptend_t_4',\n 'ptend_t_5',\n 'ptend_t_6',\n 'ptend_t_7',\n 'ptend_t_8',\n 'ptend_t_9',\n 'ptend_t_10',\n 'ptend_t_11',\n 'ptend_t_12',\n 'ptend_t_13',\n 'ptend_t_14',\n 'ptend_t_15',\n 'ptend_t_16',\n 'ptend_t_17',\n 'ptend_t_18',\n 'ptend_t_19',\n 'ptend_t_20',\n 'ptend_t_21',\n 'ptend_t_22',\n 'ptend_t_23',\n 'ptend_t_24',\n 'ptend_t_25',\n 'ptend_t_26',\n 'ptend_t_27',\n 'ptend_t_28',\n 'ptend_t_29',\n 'ptend_t_30',\n 'ptend_t_31',\n 'ptend_t_32',\n 'ptend_t_33',\n 'ptend_t_34',\n 'ptend_t_35',\n 'ptend_t_36',\n 'ptend_t_37',\n 'ptend_t_38',\n 'ptend_t_39',\n 'ptend_t_40',\n 'ptend_t_41',\n 'ptend_t_42',\n 'ptend_t_43',\n 'ptend_t_44',\n 'ptend_t_45',\n 'ptend_t_46',\n 'ptend_t_47',\n 'ptend_t_48',\n 'ptend_t_49',\n 'ptend_t_50',\n 'ptend_t_51',\n 'ptend_t_52',\n 'ptend_t_53',\n 'ptend_t_54',\n 'ptend_t_55',\n 'ptend_t_56',\n 'ptend_t_57',\n 'ptend_t_58',\n 'ptend_t_59',\n 'ptend_q0001_0',\n 'ptend_q0001_1',\n 'ptend_q0001_2',\n 'ptend_q0001_3',\n 'ptend_q0001_4',\n 'ptend_q0001_5',\n 'ptend_q0001_6',\n 'ptend_q0001_7',\n 'ptend_q0001_8',\n 'ptend_q0001_9',\n 'ptend_q0001_10',\n 'ptend_q0001_11',\n 'ptend_q0001_12',\n 'ptend_q0001_13',\n 'ptend_q0001_14',\n 'ptend_q0001_15',\n 'ptend_q0001_16',\n 'ptend_q0001_17',\n 'ptend_q0001_18',\n 'ptend_q0001_19',\n 'ptend_q0001_20',\n 'ptend_q0001_21',\n 'ptend_q0001_22',\n 'ptend_q0001_23',\n 'ptend_q0001_24',\n 'ptend_q0001_25',\n 'ptend_q0001_26',\n 'ptend_q0001_27',\n 'ptend_q0001_28',\n 'ptend_q0001_29',\n 'ptend_q0001_30',\n 'ptend_q0001_31',\n 'ptend_q0001_32',\n 'ptend_q0001_33',\n 'ptend_q0001_34',\n 'ptend_q0001_35',\n 'ptend_q0001_36',\n 'ptend_q0001_37',\n 'ptend_q0001_38',\n 'ptend_q0001_39',\n 'ptend_q0001_40',\n 'ptend_q0001_41',\n 'ptend_q0001_42',\n 'ptend_q0001_43',\n 'ptend_q0001_44',\n 'ptend_q0001_45',\n 'ptend_q0001_46',\n 'ptend_q0001_47',\n 'ptend_q0001_48',\n 'ptend_q0001_49',\n 'ptend_q0001_50',\n 'ptend_q0001_51',\n 'ptend_q0001_52',\n 'ptend_q0001_53',\n 'ptend_q0001_54',\n 'ptend_q0001_55',\n 'ptend_q0001_56',\n 'ptend_q0001_57',\n 'ptend_q0001_58',\n 'ptend_q0001_59',\n 'ptend_q0002_0',\n 'ptend_q0002_1',\n 'ptend_q0002_2',\n 'ptend_q0002_3',\n 'ptend_q0002_4',\n 'ptend_q0002_5',\n 'ptend_q0002_6',\n 'ptend_q0002_7',\n 'ptend_q0002_8',\n 'ptend_q0002_9',\n 'ptend_q0002_10',\n 'ptend_q0002_11',\n 'ptend_q0002_12',\n 'ptend_q0002_13',\n 'ptend_q0002_14',\n 'ptend_q0002_15',\n 'ptend_q0002_16',\n 'ptend_q0002_17',\n 'ptend_q0002_18',\n 'ptend_q0002_19',\n 'ptend_q0002_20',\n 'ptend_q0002_21',\n 'ptend_q0002_22',\n 'ptend_q0002_23',\n 'ptend_q0002_24',\n 'ptend_q0002_25',\n 'ptend_q0002_26',\n 'ptend_q0002_27',\n 'ptend_q0002_28',\n 'ptend_q0002_29',\n 'ptend_q0002_30',\n 'ptend_q0002_31',\n 'ptend_q0002_32',\n 'ptend_q0002_33',\n 'ptend_q0002_34',\n 'ptend_q0002_35',\n 'ptend_q0002_36',\n 'ptend_q0002_37',\n 'ptend_q0002_38',\n 'ptend_q0002_39',\n 'ptend_q0002_40',\n 'ptend_q0002_41',\n 'ptend_q0002_42',\n 'ptend_q0002_43',\n 'ptend_q0002_44',\n 'ptend_q0002_45',\n 'ptend_q0002_46',\n 'ptend_q0002_47',\n 'ptend_q0002_48',\n 'ptend_q0002_49',\n 'ptend_q0002_50',\n 'ptend_q0002_51',\n 'ptend_q0002_52',\n 'ptend_q0002_53',\n 'ptend_q0002_54',\n 'ptend_q0002_55',\n 'ptend_q0002_56',\n 'ptend_q0002_57',\n 'ptend_q0002_58',\n 'ptend_q0002_59',\n 'ptend_q0003_0',\n 'ptend_q0003_1',\n 'ptend_q0003_2',\n 'ptend_q0003_3',\n 'ptend_q0003_4',\n 'ptend_q0003_5',\n 'ptend_q0003_6',\n 'ptend_q0003_7',\n 'ptend_q0003_8',\n 'ptend_q0003_9',\n 'ptend_q0003_10',\n 'ptend_q0003_11',\n 'ptend_q0003_12',\n 'ptend_q0003_13',\n 'ptend_q0003_14',\n 'ptend_q0003_15',\n 'ptend_q0003_16',\n 'ptend_q0003_17',\n 'ptend_q0003_18',\n 'ptend_q0003_19',\n 'ptend_q0003_20',\n 'ptend_q0003_21',\n 'ptend_q0003_22',\n 'ptend_q0003_23',\n 'ptend_q0003_24',\n 'ptend_q0003_25',\n 'ptend_q0003_26',\n 'ptend_q0003_27',\n 'ptend_q0003_28',\n 'ptend_q0003_29',\n 'ptend_q0003_30',\n 'ptend_q0003_31',\n 'ptend_q0003_32',\n 'ptend_q0003_33',\n 'ptend_q0003_34',\n 'ptend_q0003_35',\n 'ptend_q0003_36',\n 'ptend_q0003_37',\n 'ptend_q0003_38',\n 'ptend_q0003_39',\n 'ptend_q0003_40',\n 'ptend_q0003_41',\n 'ptend_q0003_42',\n 'ptend_q0003_43',\n 'ptend_q0003_44',\n 'ptend_q0003_45',\n 'ptend_q0003_46',\n 'ptend_q0003_47',\n 'ptend_q0003_48',\n 'ptend_q0003_49',\n 'ptend_q0003_50',\n 'ptend_q0003_51',\n 'ptend_q0003_52',\n 'ptend_q0003_53',\n 'ptend_q0003_54',\n 'ptend_q0003_55',\n 'ptend_q0003_56',\n 'ptend_q0003_57',\n 'ptend_q0003_58',\n 'ptend_q0003_59',\n 'ptend_u_0',\n 'ptend_u_1',\n 'ptend_u_2',\n 'ptend_u_3',\n 'ptend_u_4',\n 'ptend_u_5',\n 'ptend_u_6',\n 'ptend_u_7',\n 'ptend_u_8',\n 'ptend_u_9',\n 'ptend_u_10',\n 'ptend_u_11',\n 'ptend_u_12',\n 'ptend_u_13',\n 'ptend_u_14',\n 'ptend_u_15',\n 'ptend_u_16',\n 'ptend_u_17',\n 'ptend_u_18',\n 'ptend_u_19',\n 'ptend_u_20',\n 'ptend_u_21',\n 'ptend_u_22',\n 'ptend_u_23',\n 'ptend_u_24',\n 'ptend_u_25',\n 'ptend_u_26',\n 'ptend_u_27',\n 'ptend_u_28',\n 'ptend_u_29',\n 'ptend_u_30',\n 'ptend_u_31',\n 'ptend_u_32',\n 'ptend_u_33',\n 'ptend_u_34',\n 'ptend_u_35',\n 'ptend_u_36',\n 'ptend_u_37',\n 'ptend_u_38',\n 'ptend_u_39',\n 'ptend_u_40',\n 'ptend_u_41',\n 'ptend_u_42',\n 'ptend_u_43',\n 'ptend_u_44',\n 'ptend_u_45',\n 'ptend_u_46',\n 'ptend_u_47',\n 'ptend_u_48',\n 'ptend_u_49',\n 'ptend_u_50',\n 'ptend_u_51',\n 'ptend_u_52',\n 'ptend_u_53',\n 'ptend_u_54',\n 'ptend_u_55',\n 'ptend_u_56',\n 'ptend_u_57',\n 'ptend_u_58',\n 'ptend_u_59',\n 'ptend_v_0',\n 'ptend_v_1',\n 'ptend_v_2',\n 'ptend_v_3',\n 'ptend_v_4',\n 'ptend_v_5',\n 'ptend_v_6',\n 'ptend_v_7',\n 'ptend_v_8',\n 'ptend_v_9',\n 'ptend_v_10',\n 'ptend_v_11',\n 'ptend_v_12',\n 'ptend_v_13',\n 'ptend_v_14',\n 'ptend_v_15',\n 'ptend_v_16',\n 'ptend_v_17',\n 'ptend_v_18',\n 'ptend_v_19',\n 'ptend_v_20',\n 'ptend_v_21',\n 'ptend_v_22',\n 'ptend_v_23',\n 'ptend_v_24',\n 'ptend_v_25',\n 'ptend_v_26',\n 'ptend_v_27',\n 'ptend_v_28',\n 'ptend_v_29',\n 'ptend_v_30',\n 'ptend_v_31',\n 'ptend_v_32',\n 'ptend_v_33',\n 'ptend_v_34',\n 'ptend_v_35',\n 'ptend_v_36',\n 'ptend_v_37',\n 'ptend_v_38',\n 'ptend_v_39',\n 'ptend_v_40',\n 'ptend_v_41',\n 'ptend_v_42',\n 'ptend_v_43',\n 'ptend_v_44',\n 'ptend_v_45',\n 'ptend_v_46',\n 'ptend_v_47',\n 'ptend_v_48',\n 'ptend_v_49',\n 'ptend_v_50',\n 'ptend_v_51',\n 'ptend_v_52',\n 'ptend_v_53',\n 'ptend_v_54',\n 'ptend_v_55',\n 'ptend_v_56',\n 'ptend_v_57',\n 'ptend_v_58',\n 'ptend_v_59',\n 'cam_out_NETSW',\n 'cam_out_FLWDS',\n 'cam_out_PRECSC',\n 'cam_out_PRECC',\n 'cam_out_SOLS',\n 'cam_out_SOLL',\n 'cam_out_SOLSD',\n 'cam_out_SOLLD']"},"metadata":{}}]},{"cell_type":"code","source":"del df_train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-07-16T16:46:26.639815Z","iopub.execute_input":"2024-07-16T16:46:26.640326Z","iopub.status.idle":"2024-07-16T16:46:28.114635Z","shell.execute_reply.started":"2024-07-16T16:46:26.640290Z","shell.execute_reply":"2024-07-16T16:46:28.113348Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"90"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-16T16:46:00.133634Z","iopub.execute_input":"2024-07-16T16:46:00.134093Z","iopub.status.idle":"2024-07-16T16:46:00.162102Z","shell.execute_reply.started":"2024-07-16T16:46:00.134058Z","shell.execute_reply":"2024-07-16T16:46:00.160652Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array([-1.32552311e-02, -4.14982811e-03, -5.66318855e-02, -1.69730056e-02,\n        2.06712186e-02,  6.52998984e-02,  9.44697931e-02,  9.14321467e-02,\n        9.66449082e-02,  1.08857006e-01,  1.03046291e-01,  9.82882157e-02,\n        9.78412926e-02,  8.99169892e-02,  8.54050815e-02,  9.81084853e-02,\n        1.21981725e-01,  1.10161580e-01,  5.51250204e-02,  3.89608066e-03,\n       -7.47085288e-02, -7.01557696e-02, -7.57217482e-02, -3.05965412e-02,\n        1.86102726e-02,  6.53694794e-02,  9.83350426e-02,  1.23026609e-01,\n        1.44744471e-01,  1.58854455e-01,  1.68501899e-01,  1.70721933e-01,\n        1.71828687e-01,  1.70129851e-01,  1.64476871e-01,  1.61277086e-01,\n        1.56901315e-01,  1.50220811e-01,  1.50779739e-01,  1.49541050e-01,\n        1.47583395e-01,  1.40399694e-01,  1.33488148e-01,  1.29677147e-01,\n        1.25084072e-01,  1.24075353e-01,  1.20844051e-01,  1.18244655e-01,\n        1.14833243e-01,  1.12382591e-01,  1.09002866e-01,  1.06163077e-01,\n        1.04597658e-01,  1.01244926e-01,  9.74240303e-02,  9.23139974e-02,\n        8.51207152e-02,  7.91356638e-02,  7.26774260e-02,  7.05060363e-02,\n        1.85272518e-06,  1.87686169e-06,  1.90165349e-06,  1.90555750e-06,\n        1.90522405e-06,  1.90389346e-06,  1.92511425e-06,  1.95468579e-06,\n        1.96282281e-06,  1.96478618e-06,  1.97907093e-06,  2.01303601e-06,\n        2.05542415e-06,  2.37189147e-06,  2.70798023e-06,  2.79179562e-06,\n        2.79238361e-06,  2.94128449e-06,  5.65724531e-06,  7.56163581e-06,\n        8.01774331e-06,  1.19337774e-05,  1.59304091e-05,  3.11197400e-05,\n        6.44748288e-05,  1.26206141e-04,  2.11429753e-04,  3.37275007e-04,\n        5.24715520e-04,  8.12971382e-04,  1.20596052e-03,  1.64102786e-03,\n        2.10577482e-03,  2.58517638e-03,  3.15087964e-03,  3.92774260e-03,\n        4.61986242e-03,  5.31154033e-03,  5.86753339e-03,  6.33875746e-03,\n        6.93137059e-03,  7.50873052e-03,  8.09468701e-03,  8.63478240e-03,\n        9.33250971e-03,  9.90834087e-03,  1.04851201e-02,  1.10824574e-02,\n        1.17302518e-02,  1.21274935e-02,  1.24603789e-02,  1.28717832e-02,\n        1.31440759e-02,  1.35608856e-02,  1.40858339e-02,  1.45584596e-02,\n        1.50483400e-02,  1.56746469e-02,  1.63214523e-02,  1.66164227e-02,\n        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n        6.25252072e-11,  0.00000000e+00,  7.11976131e-03,  3.90919983e-01,\n        7.43020892e-01,  8.03959191e-01,  6.74785256e-01,  8.32383394e-01,\n        8.87594461e-01,  9.35648918e-01,  8.71098936e-01,  6.20144963e-01,\n        5.24599314e-01,  3.57524097e-01,  6.13843858e-01,  3.88900459e-01,\n        1.78438947e-01,  3.24067026e-01,  6.54290855e-01,  7.28496671e-01,\n        9.17155862e-01,  5.86688817e-01,  5.28930724e-01,  6.30934417e-01,\n        4.24036294e-01,  3.08868557e-01,  6.25392199e-01,  4.99551296e-01,\n        7.54497051e-01,  5.16930878e-01,  3.78015861e-02,  5.11061773e-03,\n        1.22923893e-12,  1.04016795e-12,  8.97171226e-13,  8.94617713e-13,\n        8.39106562e-13,  7.49622586e-13,  5.54667423e-13,  2.97761815e-13,\n        1.94066985e-13,  1.16795462e-13,  6.85007606e-14,  1.53210777e-14,\n        2.23532304e-11,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n        0.00000000e+00,  6.87672141e-13,  9.35699589e-08,  1.21311336e-04,\n        1.00805787e-02,  1.52303940e-02,  5.71697988e-02,  2.14031294e-01,\n        6.95767939e-01,  9.67237771e-01,  9.89014566e-01,  9.80780482e-01,\n        9.54969347e-01,  9.63658869e-01,  9.81170237e-01,  9.78371859e-01,\n        9.72655714e-01,  9.21186149e-01,  6.45813644e-01,  6.89122021e-01,\n        5.41575193e-01,  3.57721120e-01,  0.00000000e+00,  0.00000000e+00,\n        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n        0.00000000e+00,  0.00000000e+00,  1.30755916e-06,  3.27007479e-06,\n        2.23194164e-07,  0.00000000e+00,  0.00000000e+00,  1.15999546e-06,\n        2.46685295e-06,  2.36549272e-06,  5.98933923e-07,  3.63724735e-06,\n        4.62990829e-06,  3.72528825e-06,  2.22847552e-06,  1.09330608e-06,\n       -1.62686005e-01, -2.00794384e-01, -2.25605845e-01, -2.05659434e-01,\n       -2.00071469e-01, -1.77699059e-01, -1.58296809e-01, -1.35214597e-01,\n       -1.24544650e-01, -1.15995936e-01, -1.03516966e-01, -9.27093998e-02,\n       -8.07553977e-02, -6.23491406e-02, -3.82481515e-02, -1.71624273e-02,\n        1.86412036e-03,  5.11919986e-03, -1.81240421e-02, -4.86694165e-02,\n       -6.49779513e-02, -7.64919370e-02, -8.44012424e-02, -8.74098465e-02,\n       -8.17846879e-02, -7.71349370e-02, -7.19902813e-02, -6.59762919e-02,\n       -6.00992851e-02, -5.22543862e-02, -4.30593155e-02, -3.20960693e-02,\n       -2.02515330e-02, -7.49095483e-03,  5.70654776e-03,  1.94657799e-02,\n        3.16855609e-02,  4.34806347e-02,  5.27663529e-02,  6.14994839e-02,\n        6.98800534e-02,  7.32337534e-02,  7.57778883e-02,  7.67970011e-02,\n        7.89476559e-02,  8.05321857e-02,  8.30741823e-02,  8.58142078e-02,\n        8.81670117e-02,  9.18291584e-02,  9.26261768e-02,  9.50360224e-02,\n        1.00324512e-01,  1.02979809e-01,  9.89626721e-02,  9.88634303e-02,\n        1.05893753e-01,  1.16908453e-01,  1.08697183e-01,  9.77737829e-02,\n       -3.36801112e-02, -1.12039046e-02,  1.50179269e-03,  1.98787581e-02,\n        2.26764865e-02,  5.70681645e-03, -8.54711514e-03, -9.59593710e-03,\n       -4.82352031e-03,  2.03604781e-04,  3.74550256e-03,  4.73622512e-03,\n        5.33789607e-05, -9.03109182e-03, -1.08632939e-02, -1.33128036e-02,\n       -2.87322365e-02, -2.60657333e-02, -3.28979790e-02, -6.67992234e-02,\n       -1.04859054e-01, -1.25113755e-01, -1.45966679e-01, -1.55028895e-01,\n       -1.40872598e-01, -1.24024644e-01, -1.07587226e-01, -9.55508649e-02,\n       -8.59409198e-02, -7.74722323e-02, -7.02270791e-02, -6.34772331e-02,\n       -5.51782101e-02, -4.78785150e-02, -4.23305109e-02, -3.81910540e-02,\n       -3.51871289e-02, -3.08107771e-02, -2.53518168e-02, -1.99841075e-02,\n       -1.46539174e-02, -9.41336527e-03, -4.77628643e-03, -1.02062756e-03,\n        1.95406727e-03,  5.14149712e-03,  8.46324582e-03,  1.23941088e-02,\n        1.70864556e-02,  2.04932205e-02,  2.31804736e-02,  2.51807384e-02,\n        2.61218809e-02,  2.71960441e-02,  2.97192540e-02,  3.35149020e-02,\n        3.99701223e-02,  5.23610748e-02,  7.03919232e-02,  7.84016252e-02,\n        9.49654654e-02,  3.57456893e-01,  2.30269302e-02, -1.18481868e-03,\n       -8.50034319e-03, -9.77091677e-03,  1.31116629e-01, -5.04733980e-01,\n       -4.65579718e-01, -4.94301289e-01, -4.55501825e-01,  5.55445626e-02,\n        0.00000000e+00,  0.00000000e+00,  1.00000000e+00, -5.31366989e-02,\n        2.52879687e-07,  4.55448912e-07,  8.16349029e-07,  1.45002593e-06,\n        2.53805388e-06,  4.34879894e-06,  7.24536585e-06,  1.14856966e-05,\n        1.27341764e-05,  1.36548097e-05,  1.29671544e-05,  1.16609490e-05,\n        9.68841596e-06,  7.47339482e-06,  5.20959884e-06,  3.50414848e-06,\n        2.27977307e-06,  1.33611411e-06,  7.69953772e-07,  5.16807063e-07,\n        4.00891224e-07,  3.22833102e-07,  2.54433274e-07,  2.00080123e-07,\n        1.76525234e-07,  1.60556439e-07,  1.51564109e-07,  1.46228601e-07,\n        1.41742532e-07,  1.38122601e-07,  1.34588646e-07,  1.30074582e-07,\n        1.24908610e-07,  1.19681204e-07,  1.14666882e-07,  1.09528379e-07,\n        1.04779645e-07,  1.00364772e-07,  9.59759063e-08,  9.22039973e-08,\n        8.90038550e-08,  8.59498570e-08,  8.30522424e-08,  7.95024917e-08,\n        7.61215233e-08,  7.29066016e-08,  6.98558296e-08,  6.68572042e-08,\n        6.40343956e-08,  6.13974862e-08,  5.89301941e-08,  5.68717873e-08,\n        5.54422641e-08,  5.40512062e-08,  5.26768709e-08,  5.13032141e-08,\n        5.08009990e-08,  5.03846529e-08,  4.99599935e-08,  4.93827699e-08,\n        1.65438962e-07,  1.90004116e-07,  2.17969912e-07,  2.49519132e-07,\n        2.84649985e-07,  3.23102597e-07,  3.64337893e-07,  4.07602272e-07,\n        4.52075000e-07,  4.97045050e-07,  5.42035480e-07,  5.86812007e-07,\n        6.31277260e-07,  6.75317381e-07,  7.18695105e-07,  7.61048682e-07,\n        8.01990268e-07,  8.41235760e-07,  8.78684489e-07,  9.14402733e-07,\n        9.48527429e-07,  9.81151857e-07,  9.98605856e-07,  9.98605856e-07,\n        9.98605856e-07,  9.98605856e-07,  9.98605856e-07,  9.98605856e-07,\n        9.98605856e-07,  9.98605856e-07,  9.98605856e-07,  9.98605856e-07,\n        9.98605856e-07,  9.98605856e-07,  9.98605856e-07,  9.98605856e-07,\n        9.98605856e-07,  9.98605856e-07,  9.98605856e-07,  9.98605856e-07,\n        9.98605856e-07,  9.98605856e-07,  9.98605856e-07,  9.98605856e-07,\n        9.98605856e-07,  9.98605856e-07,  9.98605856e-07,  9.98605856e-07,\n        9.98605856e-07,  9.98605856e-07,  9.98605856e-07,  9.98605856e-07,\n        9.98605856e-07,  9.98605856e-07,  9.98605856e-07,  9.98605856e-07,\n        9.98605856e-07,  9.98605856e-07,  9.98605856e-07,  9.98605856e-07,\n        2.40679388e-08,  3.03587164e-08,  3.82211098e-08,  4.79479105e-08,\n        5.98026233e-08,  7.39635269e-08,  9.04709339e-08,  1.09205601e-07,\n        1.29920295e-07,  1.52319203e-07,  1.76145903e-07,  2.01228389e-07,\n        2.27453839e-07,  2.54692395e-07,  2.82724329e-07,  3.11223545e-07,\n        3.39813681e-07,  3.68164024e-07,  3.96065246e-07,  4.23438820e-07,\n        4.50276815e-07,  4.76553964e-07,  4.90858383e-07,  4.90858383e-07,\n        4.90858383e-07,  4.90858383e-07,  4.90858383e-07,  4.90858383e-07,\n        4.90858383e-07,  4.90858383e-07,  4.90858383e-07,  4.90858383e-07,\n        4.90858383e-07,  4.90858383e-07,  4.90858383e-07,  4.90858383e-07,\n        4.90858383e-07,  4.90858383e-07,  4.90858383e-07,  4.90858383e-07,\n        4.90858383e-07,  4.90858383e-07,  4.90858383e-07,  4.90858383e-07,\n        4.90858383e-07,  4.90858383e-07,  4.90858383e-07,  4.90858383e-07,\n        4.90858383e-07,  4.90858383e-07,  4.90858383e-07,  4.90858383e-07,\n        4.90858383e-07,  4.90858383e-07,  4.90858383e-07,  4.90858383e-07,\n        4.90858383e-07,  4.90858383e-07,  4.90858383e-07,  4.90858383e-07],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"del x_train \ndel y_train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T16:17:40.067864Z","iopub.execute_input":"2024-07-15T16:17:40.068753Z","iopub.status.idle":"2024-07-15T16:17:40.262844Z","shell.execute_reply.started":"2024-07-15T16:17:40.068715Z","shell.execute_reply":"2024-07-15T16:17:40.261897Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"markdown","source":"# NN training","metadata":{}},{"cell_type":"code","source":"seed_everything()\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:45:24.068146Z","iopub.execute_input":"2024-07-17T14:45:24.068524Z","iopub.status.idle":"2024-07-17T14:45:24.143110Z","shell.execute_reply.started":"2024-07-17T14:45:24.068485Z","shell.execute_reply":"2024-07-17T14:45:24.142271Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class ClimateDataset(Dataset):\n    def __init__(self, x, y):\n        \"\"\"\n        Initialize with NumPy arrays.\n        \"\"\"\n        assert x.shape[0] == y.shape[0], \"Features and labels must have the same number of samples\"\n        self.x = x\n        self.y = y\n\n    def __len__(self):\n        \"\"\"\n        Total number of samples.\n        \"\"\"\n        return self.x.shape[0]\n\n    def __getitem__(self, index):\n        \"\"\"\n        Generate one sample of data.\n        \"\"\"\n        # Convert the data to tensors when requested\n        return torch.from_numpy(self.x[index]).float().to(device), torch.from_numpy(self.y[index]).float().to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:45:24.144301Z","iopub.execute_input":"2024-07-17T14:45:24.144613Z","iopub.status.idle":"2024-07-17T14:45:24.152120Z","shell.execute_reply.started":"2024-07-17T14:45:24.144583Z","shell.execute_reply":"2024-07-17T14:45:24.150952Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset = ClimateDataset(x_train, y_train)\n\ntrain_size = int(0.9 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:45:24.153414Z","iopub.execute_input":"2024-07-17T14:45:24.153859Z","iopub.status.idle":"2024-07-17T14:45:24.468656Z","shell.execute_reply.started":"2024-07-17T14:45:24.153827Z","shell.execute_reply":"2024-07-17T14:45:24.467779Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class FFNN(nn.Module):\n    def __init__(self, input_size, hidden_sizes, output_size):\n        super(FFNN, self).__init__()\n        \n        layers = []\n        previous_size = input_size\n        for hidden_size in hidden_sizes:\n            layers.append(nn.Linear(previous_size, hidden_size))\n#             layers.append(nn.LayerNorm(hidden_size))\n            layers.append(nn.BatchNorm1d(hidden_size))\n            layers.append(nn.ELU(inplace=True))\n#             layers.append(nn.LeakyReLU(inplace=True))\n            layers.append(nn.Dropout(p=0.3))\n            previous_size = hidden_size\n        \n#         layers.append(nn.Linear(previous_size, output_size))\n        \n        self.layers = nn.Sequential(*layers)\n        self.output = nn.ModuleList([nn.Linear(previous_size, 1) for _ in range(output_size)])\n        \n    def forward(self, x):\n        x =  self.layers(x)\n        outputs = [output_layer(x) for output_layer in self.output]\n        outputs = torch.cat(outputs, dim=1)\n        return outputs","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FFNN(nn.Module):\n    def __init__(self, input_size, hidden_sizes, output_size):\n        super(FFNN, self).__init__()\n        \n        layers = []\n        previous_size = input_size\n        for hidden_size in hidden_sizes:\n            layers.append(nn.Linear(previous_size, hidden_size))\n            layers.append(nn.BatchNorm1d(hidden_size))\n            layers.append(nn.ELU(inplace=True))\n            layers.append(nn.Dropout(p=0.5))\n            previous_size = hidden_size\n        \n        self.layers = nn.Sequential(*layers)\n        self.output_layers = nn.ModuleList([nn.Sequential(\n            nn.Linear(previous_size, 128),\n            nn.BatchNorm1d(128),\n            nn.ELU(inplace=True),\n            nn.Dropout(p=0.5),\n            nn.Linear(128, 64),\n            nn.BatchNorm1d(64),\n            nn.ELU(inplace=True),\n            nn.Dropout(p=0.5),\n            nn.Linear(64, 1)\n        ) for _ in range(output_size)])\n        \n    def forward(self, x):\n        x = self.layers(x)\n        outputs = [output_layer(x) for output_layer in self.output_layers]\n        outputs = torch.cat(outputs, dim=1)\n        return outputs","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FFNN(nn.Module):\n    def __init__(self, input_size, hidden_sizes, output_size):\n        super(FFNN, self).__init__()\n        \n        layers = []\n        previous_size = input_size\n        for hidden_size in hidden_sizes:\n            layers.append(nn.Linear(previous_size, hidden_size))\n            layers.append(nn.BatchNorm1d(hidden_size))\n            layers.append(nn.ELU(inplace=True))\n            layers.append(nn.Dropout(p=0.3))\n            previous_size = hidden_size\n        \n        self.layers = nn.Sequential(*layers)\n        \n        # Adding more layers to the final regression head\n        self.output_layers = nn.ModuleList([nn.Sequential(\n            nn.Linear(previous_size, 128),\n            nn.BatchNorm1d(128),\n            nn.ELU(inplace=True),\n            nn.Dropout(p=0.3),\n            nn.Linear(128, 64),\n            nn.BatchNorm1d(64),\n            nn.ELU(inplace=True),\n            nn.Dropout(p=0.3),\n            nn.Linear(64, 1)\n        ) for _ in range(output_size)])\n        \n    def forward(self, x):\n        x = self.layers(x)\n        outputs = [output_layer(x) for output_layer in self.output_layers]\n        outputs = torch.cat(outputs, dim=1)\n        return outputs","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_size = x_train.shape[1]\noutput_size = y_train.shape[1]\n# hidden_size = 100 #input_size + output_size\n# model = FFNN(input_size, [hidden_size, int(0.5*hidden_size), int(0.5*hidden_size), hidden_size], output_size).to(device)\nhidden_sizes = [512, 256, 128, 64, 128, 256, 512]#[256, 128, 64, 128, 256]\nmodel = FFNN(input_size, hidden_sizes, output_size).to(device)\ncriterion = nn.HuberLoss()#nn.MSELoss() #nn.HuberLoss()#\noptimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.001)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=SCHEDULER_FACTOR, patience=SCHEDULER_PATIENCE)\n\nprint(\"Time after all preparations:\", format_time(time.time()-ts), flush=True)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_val_loss = float('inf')\nbest_r2_score = -1000\nbest_model_state = None\npatience_count = 0\nr2score = R2Score(num_outputs=len(TARGET_COLS)).to(device)\nEPOCHS = 80\nfor epoch in range(EPOCHS):\n    print(\"\")\n    model.train()\n    total_loss = 0\n    steps = 0\n    for batch_idx, (inputs, labels) in enumerate(train_loader):\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        steps += 1\n\n        if (batch_idx + 1) % PRINT_FREQ == 0:\n            current_lr = optimizer.param_groups[0][\"lr\"]\n            elapsed_time = format_time(time.time() - ts)\n            print(f'  Epoch: {epoch+1}',\\\n                  f'  Batch: {batch_idx + 1}/{len(train_loader)}',\\\n                  f'  Train Loss: {total_loss / steps:.4f}',\\\n                  f'  LR: {current_lr:.1e}',\\\n                  f'  Time: {elapsed_time}', flush=True)\n            total_loss = 0\n            steps = 0\n    \n\n    model.eval()\n    val_loss = 0\n    y_true = torch.tensor([], device=device)\n    all_outputs = torch.tensor([], device=device)\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            outputs = model(inputs)\n            val_loss += criterion(outputs, labels).item()\n            y_true = torch.cat((y_true, labels), 0)\n            all_outputs = torch.cat((all_outputs, outputs), 0)\n    r2=0\n    r2_broken = []\n    r2_broken_names = []\n    for i in range(368):\n        r2_i = r2score(all_outputs[:, i], y_true[:, i])\n        if r2_i > 1e-6:\n            r2 += r2_i\n        else:\n            r2_broken.append(i)\n            r2_broken_names.append(FEAT_COLS[i])\n#     r2 = r2score(all_outputs,y_true)\n    r2 /= 368\n\n    avg_val_loss = val_loss / len(val_loader)\n    print(f'\\nEpoch: {epoch+1}  Val Loss: {avg_val_loss:.4f}  R2 score: {r2:.4f}')\n    print(f'{len(r2_broken)} targets were excluded during evaluation of R2 score.')\n    # print(r2_broken)\n    # print(r2_broken_names, flush=True)\n   \n    scheduler.step(avg_val_loss)\n\n#     if avg_val_loss < best_val_loss:\n    if r2 > best_r2_score:\n        best_model_state = model.state_dict()\n        best_r2_score = r2\n        print(\"R2 score improved, saving new best model.\")\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        patience_count = 0\n        print(\"Validation loss decreased, resetting patience counter.\")\n    else:\n        patience_count += 1\n        print(f\"No improvement in validation loss for {patience_count} epochs.\")\n        \n    if patience_count >= PATIENCE:\n        print(\"Stopping early due to no improvement in validation loss.\")\n        break\n\n# del x_train, y_train\n# gc.collect()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 80\nbest_val_loss = float('inf')\nbest_r2_score = -1000\nbest_model_state = None\npatience_count = 0\nPATCIENCE = 10\nPRINT_FREQ = 50\n\nmodel = CustomModel_Unet_MLP(input_dim, output_dim, hidden_size)\ncriterion = nn.MSELoss()\noptimizer = optim.AdamW(model.parameters(), lr=0.001)\nscheduler = OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=num_epochs)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nfor epoch in range(num_epochs):\n    print(\"\")\n    model.train()\n    total_loss = 0\n    steps = 0\n    ts = time.time()\n\n    for batch_idx, (inputs, labels) in enumerate(train_loader):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        total_loss += loss.item()\n        steps += 1\n\n        if (batch_idx + 1) % PRINT_FREQ == 0:\n            current_lr = optimizer.param_groups[0][\"lr\"]\n            elapsed_time = time.time() - ts\n            print(f'  Epoch: {epoch+1}',\\\n                  f'  Batch: {batch_idx + 1}/{len(train_loader)}',\\\n                  f'  Train Loss: {total_loss / steps:.4f}',\\\n                  f'  LR: {current_lr:.1e}',\\\n                  f'  Time: {elapsed_time:.2f}s', flush=True)\n            total_loss = 0\n            steps = 0\n\n    model.eval()\n    val_loss = 0\n    y_true = torch.tensor([], device=device)\n    all_outputs = torch.tensor([], device=device)\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            val_loss += criterion(outputs, labels).item()\n            y_true = torch.cat((y_true, labels), 0)\n            all_outputs = torch.cat((all_outputs, outputs), 0)\n\n    r2 = 0\n    r2_broken = []\n    r2_broken_names = []\n    for i in range(len(TARGET_COLS)):\n        r2_i = r2_score(y_true[:, i].cpu(), all_outputs[:, i].cpu())\n        if r2_i > 1e-6:\n            r2 += r2_i\n        else:\n            r2_broken.append(i)\n            r2_broken_names.append(FEAT_COLS[i])\n    r2 /= len(TARGET_COLS)\n\n    avg_val_loss = val_loss / len(val_loader)\n    print(f'\\nEpoch: {epoch+1}  Val Loss: {avg_val_loss:.4f}  R2 score: {r2:.4f}')\n    print(f'{len(r2_broken)} targets were excluded during evaluation of R2 score.')\n\n    scheduler.step(avg_val_loss)\n\n    if r2 > best_r2_score:\n        best_model_state = model.state_dict()\n        best_r2_score = r2\n        print(\"R2 score improved, saving new best model.\")\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        patience_count = 0\n        print(\"Validation loss decreased, resetting patience counter.\")\n    else:\n        patience_count += 1\n        print(f\"No improvement in validation loss for {patience_count} epochs.\")\n        \n    if patience_count >= PATIENCE:\n        print(\"Stopping early due to no improvement in validation loss.\")\n        break\n\nmodel.load_state_dict(best_model_state)\nprint(\"Training complete. Best R2 score: {:.4f}\".format(best_r2_score))","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NN 2","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(ConvBlock, self).__init__()\n        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1)  # \"same\" padding in TF translates to padding=1 in PyTorch\n        self.elu = nn.ELU()\n        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.elu(x)\n        x = self.conv2(x)\n        x = self.elu(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:45:24.470052Z","iopub.execute_input":"2024-07-17T14:45:24.470805Z","iopub.status.idle":"2024-07-17T14:45:24.478368Z","shell.execute_reply.started":"2024-07-17T14:45:24.470766Z","shell.execute_reply":"2024-07-17T14:45:24.477245Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"convblk = ConvBlock(25,32)\nconvblk(torch.randn(25,64)).shape","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(EncoderBlock, self).__init__()\n        self.conv_block = ConvBlock(in_channels, out_channels)\n        self.pool = nn.MaxPool1d(2)  # Maintains channel dimension\n\n    def forward(self, x):\n        x = self.conv_block(x)\n        p = self.pool(x)  # Pooling reduces sequence length by half\n        return x, p\n    \n# encoder = EncoderBlock(25,32)\n# o = encoder(torch.randn(25,64))\n# o[0].shape,o[1].shape\nclass DecoderBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DecoderBlock, self).__init__()\n        self.transpose = nn.ConvTranspose1d(in_channels, out_channels, kernel_size=2, stride=2, padding=0)  # Adjust padding for desired output size\n        self.conv_block = ConvBlock(in_channels, out_channels)  # Doubled channels after concatenation\n\n    def forward(self, x, skip):\n        x = self.transpose(x)  # Doubles sequence length, maintains channels\n#         print(x.shape,skip.shape)\n        x = torch.cat([x, skip],dim=1)  # Concatenate features, doubles channels\n#         print(x.shape)\n        x = self.conv_block(x)\n        return x\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:45:24.479522Z","iopub.execute_input":"2024-07-17T14:45:24.479805Z","iopub.status.idle":"2024-07-17T14:45:24.488659Z","shell.execute_reply.started":"2024-07-17T14:45:24.479783Z","shell.execute_reply":"2024-07-17T14:45:24.487602Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# dec = DecoderBlock(512,256)\n# dec(torch.randn(512,4),torch.randn(256,8)).shape","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, input_shape):\n        super(UNet, self).__init__()\n        self.zero_pad = nn.ZeroPad1d(2)  # Assuming you meant ZeroPadding2d (for 2D data)\n\n        # Encoder (adjust channel numbers and block definitions as needed)\n        self.s00 = EncoderBlock(input_shape[0], 32)  # Input channels, output channels\n        self.s0 = EncoderBlock(32, 64)\n        self.s1 = EncoderBlock(64, 128)\n        self.s2 = EncoderBlock(128, 256)\n\n        # Bottleneck\n        self.b1 = ConvBlock(256, 512)  # Maintain channel dimension\n\n        # Decoder (adjust channel numbers and block definitions as needed)\n        self.d3 = DecoderBlock(512, 256)  # Input channels, skip channels, output channels\n        self.d4 = DecoderBlock(256, 128)\n        self.d5 = DecoderBlock(128, 64)\n        self.d6 = DecoderBlock(64, 32)\n\n        # Output\n        self.outputs = nn.Conv1d(32, 6, kernel_size=1, padding=\"same\")  # Adjust output channels as needed\n        self.cropping = nn.ConstantPad1d((2, 0), value=0)  # Assuming you want to remove padding at the end\n\n    def forward(self, x):\n        x = self.zero_pad(x)  # Pad input if necessary (assuming 2D data)\n\n        # Encoder\n#         print(x.shape)\n        s00, p00 = self.s00(x)\n#         print(s00.shape,p00.shape)\n        s0, p0 = self.s0(p00)\n#         print(s0.shape,p0.shape)\n        s1, p1 = self.s1(p0)\n#         print(s1.shape,p1.shape)\n        s2, p2 = self.s2(p1)\n#         print(s2.shape,p2.shape)\n\n        # Bottleneck\n        b1 = self.b1(p2)\n#         print(b1.shape)\n\n        # Decoder\n        d3 = self.d3(b1, s2)\n#         print(d3.shape)\n        d4 = self.d4(d3, s1)\n#         print(d4.shape)\n        d5 = self.d5(d4, s0)\n#         print(d5.shape)\n        d6 = self.d6(d5, s00)\n#         print(d6.shape)\n\n        # Output\n        outputs = self.outputs(d6)\n#         print(outputs.shape)\n        outputs = outputs[:,:,2:-2]\n        \n        \n#         outputs = self.cropping(outputs)  # Remove padding if necessary\n#         print(outputs.permute((0,2,1)).shape)\n\n        return outputs.permute((0,2,1))","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:45:24.489915Z","iopub.execute_input":"2024-07-17T14:45:24.490253Z","iopub.status.idle":"2024-07-17T14:45:24.503553Z","shell.execute_reply.started":"2024-07-17T14:45:24.490219Z","shell.execute_reply":"2024-07-17T14:45:24.502592Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"unet = UNet((25,64))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = unet(torch.randn(1,25,60))\nprint(x.shape)\n# for i in x:\n#     print(x.shape)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomModel_Unet_MLP(nn.Module):\n    def __init__(self, input_dim, output_dim, hidden_size):\n        super(CustomModel_Unet_MLP, self).__init__()\n\n        self.unet = UNet((25,64))\n        self.hidden_size = hidden_size\n        self.inp_shape = input_dim\n        self.n_layers = 6\n        self.activation_fn = 'elu'\n\n       # MLP layers\n        self.dense1 = nn.Linear(self.inp_shape, 3 * self.hidden_size)\n        self.dense2 = nn.Linear(3 * self.hidden_size, 2 * self.hidden_size)\n        self.dropout = nn.Dropout(p=0.2)\n        self.batch_norm = nn.BatchNorm1d(2 * self.hidden_size)\n        self.skip_connections = nn.ModuleList([])\n        for _ in range(self.n_layers):\n            self.skip_connections.append(nn.Linear(2 * self.hidden_size, 2 * self.hidden_size))\n            if self.activation_fn == 'relu':\n                self.skip_connections.append(nn.ReLU())\n            elif self.activation_fn == 'elu':\n                self.skip_connections.append(nn.ELU())\n            elif self.activation_fn == 'leakyRelu':\n                self.skip_connections.append(nn.LeakyReLU(negative_slope=0.15))\n        self.dense3 = nn.Linear(2 * self.hidden_size, 3 * self.hidden_size)\n        self.dense_out = nn.Linear(3 * self.hidden_size, output_dim - (60 * 6))  # Adjust output size\n\n    def forward(self, x):\n        x1 = x[:, :360]\n        x2 = x[:, 376:]\n        x3 = x[:, 360:376]\n\n        x3 = x3.unsqueeze(1).expand(-1, 60, -1)\n        x1 = x1.view(-1, 60, 6)\n        x2 = x2.view(-1, 60, 3)\n\n        cnn_input = torch.cat([x1, x3, x2], dim=-1)\n        new_shape = (cnn_input.shape[0],cnn_input.shape[2],cnn_input.shape[1])\n        cnn_out = self.unet(cnn_input.view(new_shape))\n#         print(cnn_out.shape)\n        \n       # MLP part\n        x = self.dense1(x)\n        x = self.dense2(x)\n        skip = x  # Store initial dense layer output for skip connections\n\n        for i in range(self.n_layers):\n            x = self.skip_connections[2 * i](x)\n            x = self.skip_connections[2 * i + 1](x)\n            x = self.dropout(x)\n            x = self.batch_norm(x)\n            x = x + skip  # Add skip connection\n            skip = x  # Update skip connection for next layer\n\n        x = self.dense3(x)\n        ann_out = self.dense_out(x)\n#         print(ann_out.shape)\n        cnn_out = cnn_out.reshape(-1,  cnn_out.size(1) * cnn_out.size(2))\n#         print(ann_out.shape,cnn_out.shape)\n        # Concatenate outputs\n        x = torch.cat((cnn_out, ann_out), dim=1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:45:24.504659Z","iopub.execute_input":"2024-07-17T14:45:24.505140Z","iopub.status.idle":"2024-07-17T14:45:24.541864Z","shell.execute_reply.started":"2024-07-17T14:45:24.505115Z","shell.execute_reply":"2024-07-17T14:45:24.540857Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"unet_mlp = CustomModel_Unet_MLP(556,368,556+368)\nx = unet_mlp(torch.tensor(x_train))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CustomModel_Unet_MLP(556,368,556+368).to(device)\ncriterion = nn.MSELoss()\noptimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.001)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=SCHEDULER_FACTOR, patience=SCHEDULER_PATIENCE)\n\nprint(\"Time after all preparations:\", format_time(time.time()-ts), flush=True)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nfrom torch.cuda.amp import GradScaler, autocast\nscaler = GradScaler()\ninput_dim = 556  # Example input dimension\noutput_dim = 368  # Example output dimension\nhidden_size = 556+368  # Example hidden size\n\nmodel = CustomModel_Unet_MLP(input_dim, output_dim, hidden_size)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.load_state_dict(torch.load('/kaggle/input/files2-leap/best_model_weights (1).pth'))","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:45:24.543010Z","iopub.execute_input":"2024-07-17T14:45:24.543341Z","iopub.status.idle":"2024-07-17T14:45:28.016751Z","shell.execute_reply.started":"2024-07-17T14:45:24.543316Z","shell.execute_reply":"2024-07-17T14:45:28.015803Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dummy data for illustration\n\n\ncriterion = nn.MSELoss()\noptimizer = optim.AdamW(model.parameters(), lr=0.001)\n# scheduler = OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=100, epochs=10)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=SCHEDULER_FACTOR, patience=SCHEDULER_PATIENCE)\n# Assuming train_loader and val_loader are defined\nnum_epochs = 10\n\n    \nnum_epochs = 80\nbest_val_loss = float('inf')\nbest_r2_score = 0.3425\nbest_model_state = None\npatience_count = 0\nPATCIENCE = 10\nPRINT_FREQ = 50\n\nfor epoch in range(num_epochs):\n    print(\"\")\n    model.train()\n    total_loss = 0\n    steps = 0\n    ts = time.time()\n\n    for batch_idx, (inputs, labels) in enumerate(train_loader):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n#         scheduler.step()\n\n        total_loss += loss.item()\n        steps += 1\n\n        if (batch_idx + 1) % PRINT_FREQ == 0:\n            current_lr = optimizer.param_groups[0][\"lr\"]\n            elapsed_time = time.time() - ts\n            print(f'  Epoch: {epoch+1}',\\\n                  f'  Batch: {batch_idx + 1}/{len(train_loader)}',\\\n                  f'  Train Loss: {total_loss / steps:.4f}',\\\n                  f'  LR: {current_lr:.1e}',\\\n                  f'  Time: {elapsed_time:.2f}s', flush=True)\n            total_loss = 0\n            steps = 0\n\n    model.eval()\n    val_loss = 0\n    y_true = torch.tensor([], device=device)\n    all_outputs = torch.tensor([], device=device)\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            val_loss += criterion(outputs, labels).item()\n            y_true = torch.cat((y_true, labels), 0)\n            all_outputs = torch.cat((all_outputs, outputs), 0)\n\n    r2 = 0\n    r2_broken = []\n    r2_broken_names = []\n    for i in range(len(TARGET_COLS)):\n        r2_i = r2_score(y_true[:, i].cpu(), all_outputs[:, i].cpu())\n        if r2_i > 1e-6:\n            r2 += r2_i\n        else:\n            r2_broken.append(i)\n            r2_broken_names.append(FEAT_COLS[i])\n    r2 /= len(TARGET_COLS)\n\n    avg_val_loss = val_loss / len(val_loader)\n    print(f'\\nEpoch: {epoch+1}  Val Loss: {avg_val_loss:.4f}  R2 score: {r2:.4f}')\n    print(f'{len(r2_broken)} targets were excluded during evaluation of R2 score.')\n\n    scheduler.step(avg_val_loss)\n\n    if r2 > best_r2_score:\n        best_model_state = model.state_dict()\n        best_r2_score = r2\n        model_weights_path = 'best_model_weights.pth'\n        torch.save(model.state_dict(), model_weights_path)\n        print(\"R2 score improved, saving new best model. model saved to best_model_weights.pth\")\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        patience_count = 0\n        print(\"Validation loss decreased, resetting patience counter.\")\n    else:\n        patience_count += 1\n        print(f\"No improvement in validation loss for {patience_count} epochs.\")\n        \n    if patience_count >= PATIENCE:\n        print(\"Stopping early due to no improvement in validation loss.\")\n        break\n\nmodel.load_state_dict(best_model_state)\nprint(\"Training complete. Best R2 score: {:.4f}\".format(best_r2_score))","metadata":{"execution":{"iopub.status.busy":"2024-07-17T14:45:28.020322Z","iopub.execute_input":"2024-07-17T14:45:28.020697Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\n  Epoch: 1   Batch: 50/174   Train Loss: 0.3388   LR: 1.0e-03   Time: 134.86s\n  Epoch: 1   Batch: 100/174   Train Loss: 0.3089   LR: 1.0e-03   Time: 268.61s\n  Epoch: 1   Batch: 150/174   Train Loss: 0.3084   LR: 1.0e-03   Time: 400.29s\n\nEpoch: 1  Val Loss: 0.3234  R2 score: 0.3094\n97 targets were excluded during evaluation of R2 score.\nValidation loss decreased, resetting patience counter.\n\n  Epoch: 2   Batch: 50/174   Train Loss: 0.3059   LR: 1.0e-03   Time: 132.05s\n  Epoch: 2   Batch: 100/174   Train Loss: 0.3002   LR: 1.0e-03   Time: 264.27s\n  Epoch: 2   Batch: 150/174   Train Loss: 0.3031   LR: 1.0e-03   Time: 395.34s\n\nEpoch: 2  Val Loss: 0.3398  R2 score: 0.2956\n99 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 1 epochs.\n\n  Epoch: 3   Batch: 50/174   Train Loss: 0.3028   LR: 1.0e-03   Time: 131.58s\n  Epoch: 3   Batch: 100/174   Train Loss: 0.2961   LR: 1.0e-03   Time: 263.11s\n  Epoch: 3   Batch: 150/174   Train Loss: 0.2985   LR: 1.0e-03   Time: 393.58s\n\nEpoch: 3  Val Loss: 0.3051  R2 score: 0.3334\n91 targets were excluded during evaluation of R2 score.\nValidation loss decreased, resetting patience counter.\n\n  Epoch: 4   Batch: 50/174   Train Loss: 0.2944   LR: 1.0e-03   Time: 131.64s\n  Epoch: 4   Batch: 100/174   Train Loss: 0.2928   LR: 1.0e-03   Time: 263.06s\n  Epoch: 4   Batch: 150/174   Train Loss: 0.2936   LR: 1.0e-03   Time: 394.28s\n\nEpoch: 4  Val Loss: 0.3046  R2 score: 0.3337\n91 targets were excluded during evaluation of R2 score.\nValidation loss decreased, resetting patience counter.\n\n  Epoch: 5   Batch: 50/174   Train Loss: 0.2897   LR: 1.0e-03   Time: 130.01s\n  Epoch: 5   Batch: 100/174   Train Loss: 0.2905   LR: 1.0e-03   Time: 260.59s\n  Epoch: 5   Batch: 150/174   Train Loss: 0.2887   LR: 1.0e-03   Time: 392.06s\n\nEpoch: 5  Val Loss: 0.3096  R2 score: 0.3292\n92 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 1 epochs.\n\n  Epoch: 6   Batch: 50/174   Train Loss: 0.2876   LR: 1.0e-03   Time: 131.13s\n  Epoch: 6   Batch: 100/174   Train Loss: 0.2882   LR: 1.0e-03   Time: 262.99s\n  Epoch: 6   Batch: 150/174   Train Loss: 0.2851   LR: 1.0e-03   Time: 391.98s\n\nEpoch: 6  Val Loss: 0.3023  R2 score: 0.3377\n91 targets were excluded during evaluation of R2 score.\nValidation loss decreased, resetting patience counter.\n\n  Epoch: 7   Batch: 50/174   Train Loss: 0.2830   LR: 1.0e-03   Time: 128.70s\n  Epoch: 7   Batch: 100/174   Train Loss: 0.2865   LR: 1.0e-03   Time: 256.00s\n  Epoch: 7   Batch: 150/174   Train Loss: 0.2838   LR: 1.0e-03   Time: 386.69s\n\nEpoch: 7  Val Loss: 0.3008  R2 score: 0.3390\n91 targets were excluded during evaluation of R2 score.\nValidation loss decreased, resetting patience counter.\n\n  Epoch: 8   Batch: 50/174   Train Loss: 0.2805   LR: 1.0e-03   Time: 129.21s\n  Epoch: 8   Batch: 100/174   Train Loss: 0.2821   LR: 1.0e-03   Time: 259.23s\n  Epoch: 8   Batch: 150/174   Train Loss: 0.2822   LR: 1.0e-03   Time: 388.69s\n\nEpoch: 8  Val Loss: 0.3084  R2 score: 0.3277\n100 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 1 epochs.\n\n  Epoch: 9   Batch: 50/174   Train Loss: 0.2819   LR: 1.0e-03   Time: 127.68s\n  Epoch: 9   Batch: 100/174   Train Loss: 0.2802   LR: 1.0e-03   Time: 254.18s\n  Epoch: 9   Batch: 150/174   Train Loss: 0.2801   LR: 1.0e-03   Time: 382.71s\n\nEpoch: 9  Val Loss: 0.3004  R2 score: 0.3387\n92 targets were excluded during evaluation of R2 score.\nValidation loss decreased, resetting patience counter.\n\n  Epoch: 10   Batch: 50/174   Train Loss: 0.2804   LR: 1.0e-03   Time: 129.50s\n  Epoch: 10   Batch: 100/174   Train Loss: 0.2772   LR: 1.0e-03   Time: 257.24s\n  Epoch: 10   Batch: 150/174   Train Loss: 0.2764   LR: 1.0e-03   Time: 385.90s\n\nEpoch: 10  Val Loss: 0.3273  R2 score: 0.3086\n103 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 1 epochs.\n\n  Epoch: 11   Batch: 50/174   Train Loss: 0.2825   LR: 1.0e-03   Time: 129.99s\n  Epoch: 11   Batch: 100/174   Train Loss: 0.2747   LR: 1.0e-03   Time: 259.18s\n  Epoch: 11   Batch: 150/174   Train Loss: 0.2770   LR: 1.0e-03   Time: 386.28s\n\nEpoch: 11  Val Loss: 0.2976  R2 score: 0.3424\n93 targets were excluded during evaluation of R2 score.\nValidation loss decreased, resetting patience counter.\n\n  Epoch: 12   Batch: 50/174   Train Loss: 0.2718   LR: 1.0e-03   Time: 128.76s\n  Epoch: 12   Batch: 100/174   Train Loss: 0.2720   LR: 1.0e-03   Time: 257.33s\n  Epoch: 12   Batch: 150/174   Train Loss: 0.2755   LR: 1.0e-03   Time: 384.98s\n\nEpoch: 12  Val Loss: 0.2979  R2 score: 0.3419\n92 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 1 epochs.\n\n  Epoch: 13   Batch: 50/174   Train Loss: 0.2737   LR: 1.0e-03   Time: 126.94s\n  Epoch: 13   Batch: 100/174   Train Loss: 0.2736   LR: 1.0e-03   Time: 257.10s\n  Epoch: 13   Batch: 150/174   Train Loss: 0.2709   LR: 1.0e-03   Time: 387.19s\n\nEpoch: 13  Val Loss: 0.3022  R2 score: 0.3364\n97 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 2 epochs.\n\n  Epoch: 14   Batch: 50/174   Train Loss: 0.2721   LR: 1.0e-03   Time: 130.67s\n  Epoch: 14   Batch: 100/174   Train Loss: 0.2680   LR: 1.0e-03   Time: 260.85s\n  Epoch: 14   Batch: 150/174   Train Loss: 0.2684   LR: 1.0e-03   Time: 390.48s\n\nEpoch: 14  Val Loss: 0.3020  R2 score: 0.3367\n93 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 3 epochs.\n\n  Epoch: 15   Batch: 50/174   Train Loss: 0.2715   LR: 1.0e-03   Time: 131.04s\n  Epoch: 15   Batch: 100/174   Train Loss: 0.2670   LR: 1.0e-03   Time: 263.64s\n  Epoch: 15   Batch: 150/174   Train Loss: 0.2662   LR: 1.0e-03   Time: 397.21s\n\nEpoch: 15  Val Loss: 0.3131  R2 score: 0.3223\n92 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 4 epochs.\n\n  Epoch: 16   Batch: 50/174   Train Loss: 0.2605   LR: 3.2e-04   Time: 134.14s\n  Epoch: 16   Batch: 100/174   Train Loss: 0.2547   LR: 3.2e-04   Time: 267.86s\n  Epoch: 16   Batch: 150/174   Train Loss: 0.2550   LR: 3.2e-04   Time: 400.53s\n\nEpoch: 16  Val Loss: 0.2879  R2 score: 0.3551\n92 targets were excluded during evaluation of R2 score.\nR2 score improved, saving new best model. model saved to best_model_weights.pth\nValidation loss decreased, resetting patience counter.\n\n  Epoch: 17   Batch: 50/174   Train Loss: 0.2508   LR: 3.2e-04   Time: 133.46s\n  Epoch: 17   Batch: 100/174   Train Loss: 0.2521   LR: 3.2e-04   Time: 265.97s\n  Epoch: 17   Batch: 150/174   Train Loss: 0.2523   LR: 3.2e-04   Time: 398.39s\n\nEpoch: 17  Val Loss: 0.2883  R2 score: 0.3544\n92 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 1 epochs.\n\n  Epoch: 18   Batch: 50/174   Train Loss: 0.2494   LR: 3.2e-04   Time: 131.23s\n  Epoch: 18   Batch: 100/174   Train Loss: 0.2504   LR: 3.2e-04   Time: 264.72s\n  Epoch: 18   Batch: 150/174   Train Loss: 0.2506   LR: 3.2e-04   Time: 394.75s\n\nEpoch: 18  Val Loss: 0.2886  R2 score: 0.3543\n92 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 2 epochs.\n\n  Epoch: 19   Batch: 50/174   Train Loss: 0.2501   LR: 3.2e-04   Time: 133.74s\n  Epoch: 19   Batch: 100/174   Train Loss: 0.2491   LR: 3.2e-04   Time: 264.98s\n  Epoch: 19   Batch: 150/174   Train Loss: 0.2497   LR: 3.2e-04   Time: 394.34s\n\nEpoch: 19  Val Loss: 0.2894  R2 score: 0.3525\n92 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 3 epochs.\n\n  Epoch: 20   Batch: 50/174   Train Loss: 0.2496   LR: 3.2e-04   Time: 129.28s\n  Epoch: 20   Batch: 100/174   Train Loss: 0.2481   LR: 3.2e-04   Time: 258.54s\n  Epoch: 20   Batch: 150/174   Train Loss: 0.2474   LR: 3.2e-04   Time: 390.25s\n\nEpoch: 20  Val Loss: 0.2906  R2 score: 0.3517\n92 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 4 epochs.\n\n  Epoch: 21   Batch: 50/174   Train Loss: 0.2445   LR: 1.0e-04   Time: 130.88s\n  Epoch: 21   Batch: 100/174   Train Loss: 0.2438   LR: 1.0e-04   Time: 261.13s\n  Epoch: 21   Batch: 150/174   Train Loss: 0.2446   LR: 1.0e-04   Time: 391.01s\n\nEpoch: 21  Val Loss: 0.2872  R2 score: 0.3562\n92 targets were excluded during evaluation of R2 score.\nR2 score improved, saving new best model. model saved to best_model_weights.pth\nValidation loss decreased, resetting patience counter.\n\n  Epoch: 22   Batch: 50/174   Train Loss: 0.2426   LR: 1.0e-04   Time: 131.12s\n  Epoch: 22   Batch: 100/174   Train Loss: 0.2431   LR: 1.0e-04   Time: 263.73s\n  Epoch: 22   Batch: 150/174   Train Loss: 0.2432   LR: 1.0e-04   Time: 394.29s\n\nEpoch: 22  Val Loss: 0.2880  R2 score: 0.3551\n92 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 1 epochs.\n\n  Epoch: 23   Batch: 50/174   Train Loss: 0.2431   LR: 1.0e-04   Time: 127.93s\n  Epoch: 23   Batch: 100/174   Train Loss: 0.2416   LR: 1.0e-04   Time: 255.56s\n  Epoch: 23   Batch: 150/174   Train Loss: 0.2426   LR: 1.0e-04   Time: 385.11s\n\nEpoch: 23  Val Loss: 0.2879  R2 score: 0.3552\n92 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 2 epochs.\n\n  Epoch: 24   Batch: 50/174   Train Loss: 0.2420   LR: 1.0e-04   Time: 132.75s\n  Epoch: 24   Batch: 100/174   Train Loss: 0.2411   LR: 1.0e-04   Time: 263.39s\n  Epoch: 24   Batch: 150/174   Train Loss: 0.2430   LR: 1.0e-04   Time: 396.76s\n\nEpoch: 24  Val Loss: 0.2875  R2 score: 0.3558\n92 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 3 epochs.\n\n  Epoch: 25   Batch: 50/174   Train Loss: 0.2411   LR: 1.0e-04   Time: 135.11s\n  Epoch: 25   Batch: 100/174   Train Loss: 0.2409   LR: 1.0e-04   Time: 270.53s\n  Epoch: 25   Batch: 150/174   Train Loss: 0.2422   LR: 1.0e-04   Time: 406.39s\n\nEpoch: 25  Val Loss: 0.2875  R2 score: 0.3557\n92 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 4 epochs.\n\n  Epoch: 26   Batch: 50/174   Train Loss: 0.2394   LR: 3.2e-05   Time: 135.36s\n  Epoch: 26   Batch: 100/174   Train Loss: 0.2412   LR: 3.2e-05   Time: 270.78s\n  Epoch: 26   Batch: 150/174   Train Loss: 0.2401   LR: 3.2e-05   Time: 405.95s\n\nEpoch: 26  Val Loss: 0.2878  R2 score: 0.3553\n92 targets were excluded during evaluation of R2 score.\nNo improvement in validation loss for 5 epochs.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(best_model_state)\nmodel_weights_path = 'best_model_weights.pth'\ntorch.save(model.state_dict(), model_weights_path)\nmodel_path = 'best_model.pth'\ntorch.save(model, model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_val_loss = float('inf')\nbest_r2_score = -1000\nbest_model_state = None\npatience_count = 0\nr2score = R2Score(num_outputs=len(TARGET_COLS)).to(device)\nEPOCHS = 5\nfor epoch in range(EPOCHS):\n    print(\"\")\n    model.train()\n    total_loss = 0\n    steps = 0\n    for batch_idx, (inputs, labels) in enumerate(train_loader):\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        print(outputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        steps += 1\n\n        if (batch_idx + 1) % PRINT_FREQ == 0:\n            current_lr = optimizer.param_groups[0][\"lr\"]\n            elapsed_time = format_time(time.time() - ts)\n            print(f'  Epoch: {epoch+1}',\\\n                  f'  Batch: {batch_idx + 1}/{len(train_loader)}',\\\n                  f'  Train Loss: {total_loss / steps:.4f}',\\\n                  f'  LR: {current_lr:.1e}',\\\n                  f'  Time: {elapsed_time}', flush=True)\n            total_loss = 0\n            steps = 0\n    \n\n    model.eval()\n    val_loss = 0\n    y_true = torch.tensor([], device=device)\n    all_outputs = torch.tensor([], device=device)\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            outputs = model(inputs)\n            val_loss += criterion(outputs, labels).item()\n            y_true = torch.cat((y_true, labels), 0)\n            all_outputs = torch.cat((all_outputs, outputs), 0)\n    r2=0\n    r2_broken = []\n    r2_broken_names = []\n    for i in range(368):\n        r2_i = r2score(all_outputs[:, i], y_true[:, i])\n        if r2_i > 1e-6:\n            r2 += r2_i\n        else:\n            r2_broken.append(i)\n            r2_broken_names.append(FEAT_COLS[i])\n#     r2 = r2score(all_outputs,y_true)\n    r2 /= 368\n\n    avg_val_loss = val_loss / len(val_loader)\n    print(f'\\nEpoch: {epoch+1}  Val Loss: {avg_val_loss:.4f}  R2 score: {r2:.4f}')\n    print(f'{len(r2_broken)} targets were excluded during evaluation of R2 score.')\n    # print(r2_broken)\n    # print(r2_broken_names, flush=True)\n   \n    scheduler.step(avg_val_loss)\n\n#     if avg_val_loss < best_val_loss:\n    if r2 > best_r2_score:\n        best_model_state = model.state_dict()\n        best_r2_score = r2\n        print(\"R2 score improved, saving new best model.\")\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        patience_count = 0\n        print(\"Validation loss decreased, resetting patience counter.\")\n    else:\n        patience_count += 1\n        print(f\"No improvement in validation loss for {patience_count} epochs.\")\n        \n    if patience_count >= PATIENCE:\n        print(\"Stopping early due to no improvement in validation loss.\")\n        break\n\ndel x_train, y_train\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom sklearn.model_selection import KFold\nfrom torchmetrics import R2Score\n\n# Custom imports\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\ninput_dim = x_train.shape[1]\noutput_dim = y_train.shape[1]\nhidden_size = input_dim + output_dim\n\nkf = KFold(n_splits=20, shuffle=True, random_state=42)\nMAX_LR = 1e-1\nEPOCHS = 50\nBATCH_SIZE = 10000\nEARLY_PATIENCE = 5\nPRINT_FREQ = 10\n\nbest_val_loss = float('inf')\nbest_r2_score = -1000\nbest_model_state = None\npatience_count = 0\nr2score = R2Score(num_outputs=output_dim).to(device)\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(x_train, y_train)):\n    train_dataset = TensorDataset(torch.tensor(x_train[train_idx], dtype=torch.float32), \n                                  torch.tensor(y_train[train_idx], dtype=torch.float32))\n    val_dataset = TensorDataset(torch.tensor(x_train[val_idx], dtype=torch.float32), \n                                torch.tensor(y_train[val_idx], dtype=torch.float32))\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n\n    model = CustomModel_Unet_MLP(input_dim, output_dim, hidden_size).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=MAX_LR)\n    criterion = nn.MSELoss()\n    scheduler = OneCycleLR(optimizer, max_lr=MAX_LR, epochs=EPOCHS, steps_per_epoch=len(train_loader))\n#     early_stopping = EarlyStopping(patience=EARLY_PATIENCE)\n\n    for epoch in range(EPOCHS):\n        print(\"\")\n        model.train()\n        total_loss = 0\n        steps = 0\n        ts = time.time()\n        for batch_idx, (inputs, labels) in enumerate(train_loader):\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            steps += 1\n\n            if (batch_idx + 1) % PRINT_FREQ == 0:\n                current_lr = optimizer.param_groups[0][\"lr\"]\n                elapsed_time = format_time(time.time() - ts)\n                print(f'Epoch: {epoch+1}  Batch: {batch_idx + 1}/{len(train_loader)}  '\n                      f'Train Loss: {total_loss / steps:.4f}  LR: {current_lr:.1e}  Time: {elapsed_time}', flush=True)\n                total_loss = 0\n                steps = 0\n\n        model.eval()\n        val_loss = 0\n        y_true = torch.tensor([], device=device)\n        all_outputs = torch.tensor([], device=device)\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                val_loss += criterion(outputs, labels).item()\n                y_true = torch.cat((y_true, labels), 0)\n                all_outputs = torch.cat((all_outputs, outputs), 0)\n\n        r2 = 0\n        for i in range(output_dim):\n            r2_i = r2score(all_outputs[:, i], y_true[:, i])\n            if r2_i > 1e-6:\n                r2 += r2_i\n        r2 /= output_dim\n\n        avg_val_loss = val_loss / len(val_loader)\n        print(f'\\nEpoch: {epoch+1}  Val Loss: {avg_val_loss:.4f}  R2 score: {r2:.4f}')\n\n        scheduler.step()\n\n        if r2 > best_r2_score:\n            best_model_state = model.state_dict()\n            best_r2_score = r2\n            print(\"R2 score improved, saving new best model.\")\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            patience_count = 0\n            print(\"Validation loss decreased, resetting patience counter.\")\n        else:\n            patience_count += 1\n            print(f\"No improvement in validation loss for {patience_count} epochs.\")\n        \n        if patience_count >= EARLY_PATIENCE:\n            print(\"Stopping early due to no improvement in validation loss.\")\n            break\n\n    model.load_state_dict(best_model_state)\n    break  # Remove this line to run for all folds\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"import warnings \nwarnings.filterwarnings('ignore')\n\nmodel.load_state_dict(best_model_state)\nmodel.eval()\n\n\ndf_test = pl.read_csv(DATA_PATH + \"leap-atmospheric-physics-ai-climsim/test.csv\")\n\nfor col in FEAT_COLS:\n    df_test = df_test.with_columns(pl.col(col).cast(pl.Float32))\ndf_test,list_vector_features = normalize(df_test,FEAT_COLS)\nx_test = df_test.select(FEAT_COLS).to_numpy()\n# x_test = x_test.drop(low_variance_cols).to_numpy()\n\n# x_test = (x_test - mx.reshape(1,-1)) / sx.reshape(1,-1)\noutput_size = 368\npredt = np.zeros([x_test.shape[0], output_size], dtype=np.float32)\n\ni1 = 0\nfor i in range(10000):\n    i2 = np.minimum(i1 + BATCH_SIZE, x_test.shape[0])\n    if i1 == i2:  # Break the loop if range does not change\n        break\n\n    # Convert the current slice of xt to a PyTorch tensor\n    inputs = torch.from_numpy(x_test[i1:i2, :]).float().to(device)\n\n    # No need to track gradients for inference\n    with torch.no_grad():\n        outputs = model(inputs)  # Get model predictions\n        predt[i1:i2, :] = outputs.cpu().numpy()  # Store predictions in predt\n\n    i1 = i2  # Update i1 to the end of the current batch\n\n    if i2 >= x_test.shape[0]:\n        break\n\nfor i in range(sy.shape[0]):\n    if sy[i] < MIN_STD * 1.1:\n        predt[:,i] = 0\n\npredt = predt * sy.reshape(1,-1) + my.reshape(1,-1)\n\nss = pd.read_csv(DATA_PATH + \"leap-atmospheric-physics-ai-climsim/sample_submission.csv\")\nss.iloc[:,1:] = predt\n\ndel predt\ngc.collect()\n\nuse_cols = []\nfor i in range(27):\n    use_cols.append(f\"ptend_q0002_{i}\")\n\nss2 = pd.read_csv(DATA_PATH + \"leap-atmospheric-physics-ai-climsim/sample_submission.csv\")\ndf_test = df_test.to_pandas()\nfor col in use_cols:\n    ss[col] = -df_test[col.replace(\"ptend\", \"state\")]*ss2[col]/1200.\n\ntest_polars = pl.from_pandas(ss[[\"sample_id\"]+TARGET_COLS])\ntest_polars.write_csv(\"submission.csv\")\n\nprint(\"Total time:\", format_time(time.time()-ts))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install kaggle -q","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"KAGGLE_USERNAME\"]=\"sanket086sanket\"\nos.environ[\"KAGGLE_KEY\"]=\"dae4c6b7590cd576181b55c7356952b0\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle competitions submit -c leap-atmospheric-physics-ai-climsim -f submission.csv -m \"nn_2\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}